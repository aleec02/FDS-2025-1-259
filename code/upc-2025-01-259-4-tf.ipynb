{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06329939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "VERDE = '\\033[92m'\n",
    "AZUL = '\\033[94m'\n",
    "ROJO = '\\033[91m'\n",
    "MAGENTA = '\\033[95m'\n",
    "AMARILLO = '\\033[93m'\n",
    "ENDC = '\\033[0m'\n",
    "SEPARADOR = \"=\" * 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64466730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "graficos_dir = os.path.join('data', 'graficos')\n",
    "geo_dir = os.path.join('data', 'geo')\n",
    "os.makedirs(graficos_dir, exist_ok=True)\n",
    "os.makedirs(geo_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3e935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_y_limpiar_datos():\n",
    "    \"\"\"carga y limpia los datos de youtube india con variables derivadas fundamentales\"\"\"\n",
    "    ruta_videos = os.path.join('data', 'all-data', 'INvideos_cc50_202101.csv')\n",
    "    ruta_categorias = os.path.join('data', 'all-data', 'IN_category_id.json')\n",
    "    \n",
    "    print(f\"{SEPARADOR}\\n{AZUL}Cargando y limpiando datos de YouTube India{ENDC}\")\n",
    "    \n",
    "    # cargar datos principales con progress bar\n",
    "    print(f\"{AZUL}Cargando archivo CSV...{ENDC}\")\n",
    "    df = pd.read_csv(ruta_videos, low_memory=False)\n",
    "    \n",
    "    # cargar mapeo de categorias\n",
    "    import json\n",
    "    print(f\"{AZUL}Cargando categorias...{ENDC}\")\n",
    "    with open(ruta_categorias, 'r', encoding='utf-8') as f:\n",
    "        categorias = json.load(f)\n",
    "    mapeo_categorias = {int(item['id']): item['snippet']['title'] for item in categorias['items']}\n",
    "    \n",
    "    print(f\"{AZUL}Limpiando datos...{ENDC}\")\n",
    "    columnas_numericas = ['views', 'likes', 'dislikes', 'comment_count', 'category_id']\n",
    "    \n",
    "    with tqdm(total=7, desc=\"Procesando limpieza\") as pbar:\n",
    "        # mapear categorias\n",
    "        df['category_id'] = pd.to_numeric(df['category_id'], errors='coerce').fillna(0).astype(int)\n",
    "        df['categoria_nombre'] = df['category_id'].map(mapeo_categorias)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # limpiar valores numericos\n",
    "        for col in columnas_numericas:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # limpiar valores de texto\n",
    "        for col in ['title', 'channel_title', 'description', 'tags']:\n",
    "            df[col] = df[col].fillna('')\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # limpiar valores booleanos\n",
    "        for col in ['comments_disabled', 'ratings_disabled', 'video_error_or_removed']:\n",
    "            df[col] = df[col].fillna(False)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # eliminar duplicados\n",
    "        df = df.drop_duplicates()\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # tratar outliers\n",
    "        for col in ['views', 'likes', 'dislikes', 'comment_count']:\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            limite_inferior = q1 - 3 * iqr\n",
    "            limite_superior = q3 + 3 * iqr\n",
    "            df[col] = np.clip(df[col], limite_inferior, limite_superior)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # crear variables derivadas\n",
    "        print(f\"\\n{AZUL}Creando variables derivadas fundamentales para el analisis...{ENDC}\")\n",
    "        \n",
    "        df['total_interactions'] = df['likes'] + df['dislikes']\n",
    "        df['engagement_rate'] = np.where(df['views'] > 0, df['total_interactions'] / df['views'], 0)\n",
    "        df['like_dislike_ratio'] = np.where(df['total_interactions'] > 0, \n",
    "                                           df['likes'] / df['total_interactions'], 0.5)\n",
    "        df['views_comments_ratio'] = np.where(df['comment_count'] > 0, \n",
    "                                             df['views'] / df['comment_count'], df['views'])\n",
    "        df['likes_per_view'] = np.where(df['views'] > 0, df['likes'] / df['views'], 0)\n",
    "        df['comments_per_view'] = np.where(df['views'] > 0, df['comment_count'] / df['views'], 0)\n",
    "        df['performance_tier'] = pd.cut(\n",
    "            df['views'],\n",
    "            bins=[0, df['views'].quantile(0.25), df['views'].quantile(0.75), float('inf')],\n",
    "            labels=['bajo', 'medio', 'alto'],\n",
    "            include_lowest=True\n",
    "        )\n",
    "        pbar.update(1)\n",
    "    \n",
    "    print(f\"{VERDE}Dataset procesado exitosamente: {len(df):,} registros con {len(df.columns)} columnas{ENDC}\")\n",
    "    print(f\"{VERDE}Variables derivadas creadas para analisis avanzado de engagement y performance{ENDC}\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e74a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre1_categorias_tendencia(df):\n",
    "    \"\"\"Pregunta 1: Que categorias de videos son las de mayor tendencia?\"\"\"\n",
    "    print(f\"\\n{AZUL}Pregunta 1: Que categorias de videos son las de mayor tendencia?{ENDC}\")\n",
    "    \n",
    "    # calcular frecuencia de categorias en trending\n",
    "    tendencia_categorias = df['categoria_nombre'].value_counts().head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    colors = plt.cm.Blues(np.linspace(0.4, 0.8, len(tendencia_categorias)))\n",
    "    \n",
    "    bars = plt.barh(tendencia_categorias.index[::-1], tendencia_categorias.values[::-1], \n",
    "                   color=colors, edgecolor='navy', linewidth=1.2, alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Numero de videos en tendencia', fontsize=13, fontweight='bold')\n",
    "    plt.title('Top 10 Categorias con Mayor Frecuencia en Tendencias', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # agregar valores en las barras\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + width*0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{int(width):,}', va='center', ha='left', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(graficos_dir, '01_categorias_mayor_tendencia.png')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Grafico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "    print(f\"La categoria con mas videos en tendencia es: {VERDE}{tendencia_categorias.index[0]}{ENDC}\")\n",
    "    print(f\"Total de videos: {VERDE}{tendencia_categorias.iloc[0]:,}{ENDC}\")\n",
    "    print(f\"Las top 3 categorias representan {VERDE}{(tendencia_categorias.head(3).sum()/len(df)*100):.1f}%{ENDC} del total\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f479c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre2_categorias_mayor_menor_gusto(df):\n",
    "    \"\"\"Pregunta 2: Que categorias de videos son los que mas gustan? Y las que menos gustan?\"\"\"\n",
    "    print(f\"\\n{AZUL}Pregunta 2: Que categorias de videos son los que mas gustan? Y las que menos gustan?{ENDC}\")\n",
    "    \n",
    "    # calcular likes promedio por categoria\n",
    "    likes_por_categoria = df.groupby('categoria_nombre')['likes'].agg(['mean', 'count']).reset_index()\n",
    "    likes_por_categoria = likes_por_categoria[likes_por_categoria['count'] >= 10]\n",
    "    likes_por_categoria = likes_por_categoria.sort_values('mean', ascending=False)\n",
    "    \n",
    "    top_5_mas_gustan = likes_por_categoria.head(5)\n",
    "    top_5_menos_gustan = likes_por_categoria.tail(5)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    colors_mas = plt.cm.Greens(np.linspace(0.5, 0.9, 5))\n",
    "    colors_menos = plt.cm.Reds(np.linspace(0.5, 0.9, 5))\n",
    "    \n",
    "    # grafico de categorias que mas gustan\n",
    "    bars1 = ax1.barh(top_5_mas_gustan['categoria_nombre'][::-1], \n",
    "                     top_5_mas_gustan['mean'][::-1], \n",
    "                     color=colors_mas, edgecolor='darkgreen', linewidth=1.2, alpha=0.8)\n",
    "    ax1.set_xlabel('Likes promedio', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Top 5 Categorias que MAS Gustan', fontsize=14, fontweight='bold', pad=15)\n",
    "    ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for i, bar in enumerate(bars1):\n",
    "        ax1.text(bar.get_width() + bar.get_width()*0.02, bar.get_y() + bar.get_height()/2,\n",
    "                f'{int(bar.get_width()):,}', va='center', ha='left', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # grafico de categorias que menos gustan  \n",
    "    bars2 = ax2.barh(top_5_menos_gustan['categoria_nombre'][::-1], \n",
    "                     top_5_menos_gustan['mean'][::-1], \n",
    "                     color=colors_menos, edgecolor='darkred', linewidth=1.2, alpha=0.8)\n",
    "    ax2.set_xlabel('Likes promedio', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Top 5 Categorias que MENOS Gustan', fontsize=14, fontweight='bold', pad=15)\n",
    "    ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for i, bar in enumerate(bars2):\n",
    "        ax2.text(bar.get_width() + bar.get_width()*0.02, bar.get_y() + bar.get_height()/2,\n",
    "                f'{int(bar.get_width()):,}', va='center', ha='left', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(graficos_dir, '02_categorias_mas_menos_gustan.png')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Grafico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "    print(f\"Categoria que MAS gusta: {VERDE}{top_5_mas_gustan.iloc[0]['categoria_nombre']}{ENDC}\")\n",
    "    print(f\"Promedio de likes: {VERDE}{top_5_mas_gustan.iloc[0]['mean']:,.0f}{ENDC}\")\n",
    "    print(f\"Categoria que MENOS gusta: {AMARILLO}{top_5_menos_gustan.iloc[-1]['categoria_nombre']}{ENDC}\")\n",
    "    print(f\"Promedio de likes: {AMARILLO}{top_5_menos_gustan.iloc[-1]['mean']:,.0f}{ENDC}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d17b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre3_mejor_ratio_likes_dislikes(df):\n",
    "    \"\"\"Pregunta 3: Que categorias de videos tienen la mejor proporcion (ratio) de Me gusta / No me gusta?\"\"\"\n",
    "    print(f\"\\n{AZUL}Pregunta 3: Que categorias de videos tienen la mejor proporcion (ratio) de Me gusta / No me gusta?{ENDC}\")\n",
    "    \n",
    "    # calcular ratio promedio por categoria\n",
    "    ratio_por_categoria = df[df['total_interactions'] > 0].groupby('categoria_nombre').agg({\n",
    "        'like_dislike_ratio': 'mean',\n",
    "        'video_id': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    ratio_por_categoria = ratio_por_categoria[ratio_por_categoria['video_id'] >= 15]\n",
    "    ratio_por_categoria = ratio_por_categoria.sort_values('like_dislike_ratio', ascending=False)\n",
    "    \n",
    "    top_10_ratio = ratio_por_categoria.head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(top_10_ratio)))\n",
    "    \n",
    "    bars = plt.barh(top_10_ratio['categoria_nombre'][::-1], \n",
    "                   top_10_ratio['like_dislike_ratio'][::-1],\n",
    "                   color=colors, edgecolor='darkblue', linewidth=1.2, alpha=0.85)\n",
    "    \n",
    "    plt.xlabel('Ratio Me gusta / Total interacciones', fontsize=13, fontweight='bold')\n",
    "    plt.title('Top 10 Categorias con Mejor Ratio Me gusta / No me gusta', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        ratio_val = bar.get_width()\n",
    "        percentage = ratio_val * 100\n",
    "        plt.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "                f'{ratio_val:.3f} ({percentage:.1f}%)', \n",
    "                va='center', ha='left', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.xlim(0, 1.05)\n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(graficos_dir, '03_mejor_ratio_likes_dislikes.png')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Grafico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "    print(f\"Mejor categoria en ratio likes/dislikes: {VERDE}{top_10_ratio.iloc[0]['categoria_nombre']}{ENDC}\")\n",
    "    print(f\"Ratio: {VERDE}{top_10_ratio.iloc[0]['like_dislike_ratio']:.3f}{ENDC}\")\n",
    "    print(f\"Esto significa que {VERDE}{top_10_ratio.iloc[0]['like_dislike_ratio']*100:.1f}%{ENDC} de las interacciones son likes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f4c8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre4_ratio_vistas_comentarios(df):\n",
    "    \"\"\"Pregunta 4: Que categorias de videos tienen la mejor proporcion (ratio) de Vistas / Comentarios?\"\"\"\n",
    "    print(f\"\\n{AZUL}Pregunta 4: Que categorias de videos tienen la mejor proporcion (ratio) de Vistas / Comentarios?{ENDC}\")\n",
    "    \n",
    "    # calcular metricas por categoria\n",
    "    df_con_comentarios = df[df['comment_count'] > 0]\n",
    "    ratio_vistas_comentarios = df_con_comentarios.groupby('categoria_nombre').agg({\n",
    "        'views_comments_ratio': 'mean',\n",
    "        'comments_per_view': 'mean', \n",
    "        'video_id': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    ratio_vistas_comentarios = ratio_vistas_comentarios[ratio_vistas_comentarios['video_id'] >= 10]\n",
    "    ratio_vistas_comentarios = ratio_vistas_comentarios.sort_values('comments_per_view', ascending=False)\n",
    "    \n",
    "    top_10_comentarios = ratio_vistas_comentarios.head(10)\n",
    "    \n",
    "    # crear scatterplot\n",
    "    plt.figure(figsize=(14, 9))\n",
    "    \n",
    "    # normalizar tamaños para mejor visualizacion\n",
    "    sizes = (top_10_comentarios['video_id'] - top_10_comentarios['video_id'].min() + 10) * 5\n",
    "    \n",
    "    scatter = plt.scatter(top_10_comentarios['views_comments_ratio'], \n",
    "                         top_10_comentarios['comments_per_view'] * 100,  # convertir a porcentaje\n",
    "                         s=sizes,\n",
    "                         c=range(len(top_10_comentarios)), \n",
    "                         cmap='plasma', alpha=0.7, edgecolors='black', linewidth=1.5)\n",
    "    \n",
    "    for i, row in top_10_comentarios.iterrows():\n",
    "        plt.annotate(row['categoria_nombre'], \n",
    "                    (row['views_comments_ratio'], row['comments_per_view'] * 100),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=10,\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', facecolor='white', \n",
    "                             edgecolor='gray', alpha=0.8))\n",
    "    \n",
    "    plt.xlabel('Ratio Vistas / Comentarios (menor = mas engagement)', fontsize=13, fontweight='bold')\n",
    "    plt.ylabel('Comentarios por Vista (%)', fontsize=13, fontweight='bold') \n",
    "    plt.title('Categorias con Mejor Engagement en Comentarios\\n(tamaño = numero de videos)', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Ranking', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(graficos_dir, '04_ratio_vistas_comentarios.png')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Grafico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "    print(f\"Mejor categoria en engagement de comentarios: {VERDE}{top_10_comentarios.iloc[0]['categoria_nombre']}{ENDC}\")\n",
    "    print(f\"Comentarios por vista: {VERDE}{top_10_comentarios.iloc[0]['comments_per_view']*100:.2f}%{ENDC}\")\n",
    "    print(f\"Ratio vistas/comentarios: {VERDE}{top_10_comentarios.iloc[0]['views_comments_ratio']:.1f}{ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bcf97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre5_volumen_tendencia_tiempo(df):\n",
    "    \"\"\"Pregunta 5: Como ha cambiado el volumen de los videos en tendencia a lo largo del tiempo?\"\"\"\n",
    "    print(f\"\\n{AZUL}Pregunta 5: Como ha cambiado el volumen de los videos en tendencia a lo largo del tiempo?{ENDC}\")\n",
    "    \n",
    "    if 'trending_date' in df.columns:\n",
    "        # convertir trending_date a datetime\n",
    "        df['fecha_trending'] = pd.to_datetime(df['trending_date'], errors='coerce')\n",
    "        df_fechas = df.dropna(subset=['fecha_trending'])\n",
    "        \n",
    "        # agrupar por semana\n",
    "        df_fechas['semana'] = df_fechas['fecha_trending'].dt.to_period('W')\n",
    "        volumen_semanal = df_fechas.groupby('semana').size().reset_index(name='num_videos')\n",
    "        \n",
    "        # crear grafico de linea\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # convertir periodos a fechas\n",
    "        fechas = [p.start_time for p in volumen_semanal['semana']]\n",
    "        \n",
    "        # grafico principal\n",
    "        plt.plot(fechas, volumen_semanal['num_videos'], \n",
    "                linewidth=3, color='steelblue', marker='o', markersize=6,\n",
    "                markeredgecolor='darkblue', markeredgewidth=1.5, alpha=0.9)\n",
    "        \n",
    "        # area sombreada\n",
    "        plt.fill_between(fechas, volumen_semanal['num_videos'], \n",
    "                        alpha=0.25, color='lightblue')\n",
    "        \n",
    "        # linea de promedio\n",
    "        promedio = volumen_semanal['num_videos'].mean()\n",
    "        plt.axhline(y=promedio, color='red', linestyle='--', linewidth=2, alpha=0.7,\n",
    "                   label=f'Promedio: {promedio:.0f} videos')\n",
    "        \n",
    "        plt.xlabel('Fecha (semanas)', fontsize=13, fontweight='bold')\n",
    "        plt.ylabel('Numero de videos en tendencia', fontsize=13, fontweight='bold')\n",
    "        plt.title('Evolucion Temporal del Volumen de Videos en Tendencia\\n(Agregacion Semanal)', \n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        # resaltar pico y minimo\n",
    "        max_idx = volumen_semanal['num_videos'].idxmax()\n",
    "        min_idx = volumen_semanal['num_videos'].idxmin()\n",
    "        \n",
    "        plt.annotate(f'Pico: {volumen_semanal.iloc[max_idx][\"num_videos\"]} videos',\n",
    "                    xy=(fechas[max_idx], volumen_semanal.iloc[max_idx]['num_videos']),\n",
    "                    xytext=(10, 20), textcoords='offset points',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.8),\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.3'))\n",
    "        \n",
    "        plt.annotate(f'Minimo: {volumen_semanal.iloc[min_idx][\"num_videos\"]} videos',\n",
    "                    xy=(fechas[min_idx], volumen_semanal.iloc[min_idx]['num_videos']),\n",
    "                    xytext=(10, -20), textcoords='offset points',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightcoral', alpha=0.8),\n",
    "                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.3'))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = os.path.join(graficos_dir, '05_volumen_tendencia_tiempo.png')\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Grafico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "        print(f\"Semana con mayor volumen: {VERDE}{volumen_semanal.iloc[max_idx]['semana']}{ENDC}\")\n",
    "        print(f\"Numero de videos: {VERDE}{volumen_semanal.iloc[max_idx]['num_videos']}{ENDC}\")\n",
    "        print(f\"Promedio semanal: {VERDE}{volumen_semanal['num_videos'].mean():.1f}{ENDC} videos\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"{ROJO}No se encontro la columna trending_date en los datos{ENDC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799800f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre6_canales_mayor_menor_tendencia(df):\n",
    "    \"\"\"analiza los canales con más apariciones en tendencias\"\"\"\n",
    "    print(f\"\\n{AZUL}pregunta 6: ¿Qué canales de youtube son tendencia más frecuentemente? y cuáles con menos frecuencia?{ENDC}\")\n",
    "    \n",
    "    # limpieza de nombres de canal\n",
    "    df['channel_title'] = df['channel_title'].str.strip()\n",
    "    df = df[df['channel_title'].astype(bool)]\n",
    "    \n",
    "    # análisis de frecuencia\n",
    "    canales_trending = df['channel_title'].value_counts()\n",
    "    top_canales = canales_trending.head(15)\n",
    "    top_channel = top_canales.index[0]\n",
    "    top_count = top_canales.iloc[0]\n",
    "    canales_unicos = canales_trending[canales_trending == 1]\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.rcParams['font.family'] = 'dejavu sans'\n",
    "    \n",
    "    colors = plt.cm.Blues(np.linspace(0.4, 0.8, len(top_canales)))\n",
    "    bars = plt.barh(top_canales.index[::-1], top_canales.values[::-1], \n",
    "                   color=colors, edgecolor='navy', linewidth=1.2, alpha=0.8)\n",
    "    \n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 5, bar.get_y() + bar.get_height()/2,\n",
    "                f'{int(width)}', \n",
    "                va='center', ha='left', \n",
    "                fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.xlabel('número de videos en tendencia', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('canales', fontsize=12, fontweight='bold')\n",
    "    plt.title('top 15 canales con más videos en tendencia', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = os.path.join(graficos_dir, '06_canales_tendencia_distribucion.png')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\n{VERDE}resultados clave:{ENDC}\")\n",
    "    print(f\"canal con más videos en tendencia: {VERDE}{top_channel}{ENDC}\")\n",
    "    print(f\"número de videos en tendencia: {VERDE}{top_count}{ENDC}\")\n",
    "    print(f\"\\n{VERDE}distribución de canales:{ENDC}\")\n",
    "    print(f\"- canales con 1 aparición: {AMARILLO}{len(canales_unicos):,}{ENDC} ({len(canales_unicos)/len(canales_trending)*100:.1f}%)\")\n",
    "    print(f\"- canales con 2-5 apariciones: {AMARILLO}{len(canales_trending[(canales_trending > 1) & (canales_trending <= 5)]):,}{ENDC}\")\n",
    "    print(f\"- canales con 6-10 apariciones: {AMARILLO}{len(canales_trending[(canales_trending > 5) & (canales_trending <= 10)]):,}{ENDC}\")\n",
    "    print(f\"- canales con más de 10 apariciones: {AMARILLO}{len(canales_trending[canales_trending > 10]):,}{ENDC}\")\n",
    "    print(f\"\\n{VERDE}total de canales analizados: {AMARILLO}{len(canales_trending):,}{ENDC}\")\n",
    "    print(f\"\\ngráfico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf00ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre7_estados_vistas_interacciones(df):\n",
    "    \"\"\"Pregunta 7: En que Estados se presenta el mayor numero de Vistas, Me gusta y No me gusta?\"\"\"\n",
    "    print(f\"\\n{AZUL}Pregunta 7: En que Estados se presenta el mayor numero de Vistas, Me gusta y No me gusta?{ENDC}\")\n",
    "    \n",
    "    if 'state' in df.columns:\n",
    "        # metricas por estado\n",
    "        estados_stats = df.groupby('state').agg({\n",
    "            'views': 'sum',\n",
    "            'likes': 'sum', \n",
    "            'dislikes': 'sum',\n",
    "            'video_id': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        estados_stats = estados_stats.sort_values('views', ascending=False).head(12)\n",
    "        \n",
    "        # stacked bar chart\n",
    "        fig, ax = plt.subplots(figsize=(15, 9))\n",
    "        \n",
    "        width = 0.75\n",
    "        x = np.arange(len(estados_stats))\n",
    "        \n",
    "        # normalizar para mejor visualizacion (en millones)\n",
    "        views_m = estados_stats['views'] / 1e6\n",
    "        likes_m = estados_stats['likes'] / 1e6  \n",
    "        dislikes_m = estados_stats['dislikes'] / 1e6\n",
    "        \n",
    "        # barras apiladas\n",
    "        p1 = ax.bar(x, views_m, width, label='Vistas (M)', \n",
    "                   color='steelblue', alpha=0.8, edgecolor='darkblue', linewidth=1.2)\n",
    "        p2 = ax.bar(x, likes_m, width, bottom=views_m, label='Likes (M)', \n",
    "                   color='lightgreen', alpha=0.8, edgecolor='darkgreen', linewidth=1.2)\n",
    "        p3 = ax.bar(x, dislikes_m, width, bottom=views_m + likes_m, label='Dislikes (M)', \n",
    "                   color='lightcoral', alpha=0.8, edgecolor='darkred', linewidth=1.2)\n",
    "        \n",
    "        ax.set_xlabel('Estados', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Cantidad (Millones)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title('Top 12 Estados por Vistas, Likes y Dislikes\\n(valores en millones)', \n",
    "                    fontsize=16, fontweight='bold', pad=20)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(estados_stats['state'], rotation=45, ha='right')\n",
    "        ax.legend(loc='upper right', fontsize=11)\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # agregar anotaciones en barras principales\n",
    "        for i, (idx, row) in enumerate(estados_stats.iterrows()):\n",
    "            total = views_m.iloc[i] + likes_m.iloc[i] + dislikes_m.iloc[i]\n",
    "            ax.text(i, total + total*0.01, f'{total:.1f}M', \n",
    "                   ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = os.path.join(graficos_dir, '07_estados_vistas_interacciones.png')\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        \n",
    "        # guardar datos geograficos\n",
    "        geo_filename = os.path.join(geo_dir, '07_estados_metricas.csv')\n",
    "        estados_stats.to_csv(geo_filename, index=False)\n",
    "        \n",
    "        print(f\"Grafico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "        print(f\"Datos geograficos guardados en: {MAGENTA}{geo_filename}{ENDC}\")\n",
    "        print(f\"Estado con mas vistas: {VERDE}{estados_stats.iloc[0]['state']}{ENDC}\")\n",
    "        print(f\"Total de vistas: {VERDE}{estados_stats.iloc[0]['views']:,}{ENDC}\")\n",
    "        print(f\"Total de videos: {VERDE}{estados_stats.iloc[0]['video_id']:,}{ENDC}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"{ROJO}No se encontro la columna state en los datos{ENDC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3c4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre8_tendencia_vs_comentarios_positivos(df):\n",
    "    \"\"\"Pregunta 8: Los videos en tendencia son los que mayor cantidad de comentarios positivos reciben?\"\"\"\n",
    "    print(f\"\\n{AZUL}Pregunta 8: Los videos en tendencia son los que mayor cantidad de comentarios positivos reciben?{ENDC}\")\n",
    "    \n",
    "    # analizar relacion entre performance tier y comentarios\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # preparar datos para boxplot\n",
    "    data_boxplot = []\n",
    "    labels_boxplot = []\n",
    "    colors_boxplot = ['#ffcccc', '#ffffcc', '#ccffcc']\n",
    "    \n",
    "    for tier, color in zip(['bajo', 'medio', 'alto'], colors_boxplot):\n",
    "        data = df[df['performance_tier'] == tier]['comment_count'].values\n",
    "        if len(data) > 0:\n",
    "            data_boxplot.append(data)\n",
    "            labels_boxplot.append(f'{tier.capitalize()}\\nrendimiento')\n",
    "    \n",
    "    # boxplot\n",
    "    bp = ax1.boxplot(data_boxplot, labels=labels_boxplot, patch_artist=True, \n",
    "                     showmeans=True, meanline=True, showfliers=False)\n",
    "    \n",
    "    # colorear cajas\n",
    "    for patch, color in zip(bp['boxes'], colors_boxplot):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "        patch.set_linewidth(1.5)\n",
    "    \n",
    "    ax1.set_ylabel('Numero de comentarios', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Nivel de rendimiento (basado en vistas)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Distribucion de Comentarios por Nivel de Rendimiento', \n",
    "                  fontsize=14, fontweight='bold', pad=15)\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # agregar estadisticas\n",
    "    stats_comentarios = df.groupby('performance_tier')['comment_count'].agg(['mean', 'median', 'count'])\n",
    "    \n",
    "    # segundo grafico: scatter plot con tendencia\n",
    "    ax2.scatter(df['views']/1e6, df['comment_count'], \n",
    "               alpha=0.3, s=30, c=df['likes'], cmap='viridis')\n",
    "    \n",
    "    # agregar linea de tendencia\n",
    "    z = np.polyfit(df['views']/1e6, df['comment_count'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax2.plot(df['views'].sort_values()/1e6, p(df['views'].sort_values()/1e6), \n",
    "            \"r--\", linewidth=2, alpha=0.8, label='Tendencia lineal')\n",
    "    \n",
    "    ax2.set_xlabel('Vistas (Millones)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Numero de comentarios', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Relacion entre Vistas y Comentarios\\n(color = likes)', \n",
    "                  fontsize=14, fontweight='bold', pad=15)\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # estadisticas en el primer grafico\n",
    "    textstr = 'Estadisticas promedio:\\n'\n",
    "    for tier, stats in stats_comentarios.iterrows():\n",
    "        textstr += f'{tier.capitalize()}: {stats[\"mean\"]:.0f} comentarios\\n'\n",
    "    \n",
    "    ax1.text(0.02, 0.98, textstr, transform=ax1.transAxes, fontsize=11,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', \n",
    "                                             edgecolor='gray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(graficos_dir, '08_tendencia_vs_comentarios.png')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Grafico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "    print(\"Estadisticas de comentarios por nivel de rendimiento:\")\n",
    "    for tier, stats in stats_comentarios.iterrows():\n",
    "        print(f\"  {tier.upper()}: promedio={VERDE}{stats['mean']:.1f}{ENDC}, \"\n",
    "              f\"mediana={VERDE}{stats['median']:.1f}{ENDC}, videos={VERDE}{stats['count']}{ENDC}\")\n",
    "    \n",
    "    # analisis de correlacion\n",
    "    correlacion = df['views'].corr(df['comment_count'])\n",
    "    print(f\"Correlacion vistas-comentarios: {VERDE}{correlacion:.3f}{ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3c9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pre9_prediccion_vistas_likes_dislikes(df):\n",
    "    \"\"\"Pregunta 9: Es factible predecir el numero de Vistas o Me gusta o No me gusta?\"\"\"\n",
    "    print(f\"\\n{AZUL}Pregunta 9: Es factible predecir el numero de Vistas o Me gusta o No me gusta?{ENDC}\")\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    print(f\"{AZUL}Preparando datos para modelado...{ENDC}\")\n",
    "    \n",
    "    # preparar features para prediccion\n",
    "    features_numericas = ['likes', 'dislikes', 'comment_count', 'engagement_rate']\n",
    "    \n",
    "    # limpiar datos para ML\n",
    "    df_ml = df.dropna(subset=features_numericas + ['views'])\n",
    "    df_ml = df_ml[df_ml['views'] > 0]\n",
    "    \n",
    "    X = df_ml[features_numericas]\n",
    "    y = df_ml['views']\n",
    "    \n",
    "    # split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"{AZUL}Entrenando modelos...{ENDC}\")\n",
    "    \n",
    "    # progress bar para entrenamiento\n",
    "    with tqdm(total=2, desc=\"Entrenando modelos\") as pbar:\n",
    "        # random forest\n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # linear regression\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(X_train_scaled, y_train)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    # predicciones\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "    \n",
    "    # metricas\n",
    "    rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "    lr_r2 = r2_score(y_test, y_pred_lr)\n",
    "    rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "    lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "    \n",
    "    # figura con multiples subplots\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # subplot 1: random forest\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    ax1.scatter(y_test/1e6, y_pred_rf/1e6, alpha=0.5, s=20, \n",
    "               c='forestgreen', edgecolors='darkgreen', linewidth=0.5)\n",
    "    ax1.plot([y_test.min()/1e6, y_test.max()/1e6], \n",
    "            [y_test.min()/1e6, y_test.max()/1e6], \n",
    "            'r--', linewidth=2, label='Prediccion perfecta')\n",
    "    ax1.set_xlabel('Vistas reales (Millones)', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('Vistas predichas (Millones)', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title(f'Random Forest\\nR² = {rf_r2:.3f}, MAE = {rf_mae/1e6:.2f}M', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # subplot 2: linear regression\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    ax2.scatter(y_test/1e6, y_pred_lr/1e6, alpha=0.5, s=20, \n",
    "               c='royalblue', edgecolors='darkblue', linewidth=0.5)\n",
    "    ax2.plot([y_test.min()/1e6, y_test.max()/1e6], \n",
    "            [y_test.min()/1e6, y_test.max()/1e6], \n",
    "            'r--', linewidth=2, label='Prediccion perfecta')\n",
    "    ax2.set_xlabel('Vistas reales (Millones)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('Vistas predichas (Millones)', fontsize=11, fontweight='bold') \n",
    "    ax2.set_title(f'Regresion Lineal\\nR² = {lr_r2:.3f}, MAE = {lr_mae/1e6:.2f}M', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # subplot 3: feature importance\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features_numericas,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    bars = ax3.barh(feature_importance['feature'], feature_importance['importance'],\n",
    "                    color=plt.cm.Oranges(np.linspace(0.4, 0.8, len(feature_importance))))\n",
    "    ax3.set_xlabel('Importancia', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Importancia de Features (Random Forest)', fontsize=13, fontweight='bold')\n",
    "    ax3.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        ax3.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "                f'{bar.get_width():.3f}', va='center', ha='left', fontsize=10)\n",
    "    \n",
    "    # subplot 4: residuales\n",
    "    ax4 = plt.subplot(2, 2, 4)\n",
    "    residuales_rf = y_test - y_pred_rf\n",
    "    ax4.scatter(y_pred_rf/1e6, residuales_rf/1e6, alpha=0.5, s=20, \n",
    "               c='purple', edgecolors='lightcoral', linewidth=0.5)\n",
    "    ax4.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "    ax4.set_xlabel('Prediccion (Millones)', fontsize=11, fontweight='bold')\n",
    "    ax4.set_ylabel('Residuales (Millones)', fontsize=11, fontweight='bold')\n",
    "    ax4.set_title('Analisis de Residuales - Random Forest', fontsize=13, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(graficos_dir, '09_prediccion_vistas_modelos.png')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Grafico guardado en: {MAGENTA}{filename}{ENDC}\")\n",
    "    print(\"\\nResultados de prediccion de vistas:\")\n",
    "    print(f\"  Random Forest - R²: {VERDE}{rf_r2:.3f}{ENDC}, MAE: {VERDE}{rf_mae/1e6:.2f}M{ENDC}\")\n",
    "    print(f\"  Regresion Lineal - R²: {VERDE}{lr_r2:.3f}{ENDC}, MAE: {VERDE}{lr_mae/1e6:.2f}M{ENDC}\")\n",
    "    print(\"\\nImportancia de features (Random Forest):\")\n",
    "    for _, row in feature_importance.iterrows():\n",
    "        print(f\"  {row['feature']}: {VERDE}{row['importance']:.3f}{ENDC}\")\n",
    "    \n",
    "    mejor_modelo = \"Random Forest\" if rf_r2 > lr_r2 else \"Regresion Lineal\"\n",
    "    print(f\"\\nConclusion: {VERDE}SI es factible predecir vistas{ENDC}\")\n",
    "    print(f\"Mejor modelo: {VERDE}{mejor_modelo}{ENDC}\")\n",
    "    print(f\"El modelo explica el {VERDE}{max(rf_r2, lr_r2)*100:.1f}%{ENDC} de la variabilidad en las vistas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca39973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "\u001b[94mCargando y limpiando datos de YouTube India\u001b[0m\n",
      "\u001b[94mCargando archivo CSV...\u001b[0m\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\all-data\\\\INvideos_cc50_202101.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEPARADOR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     df = \u001b[43mcargar_y_limpiar_datos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     preguntas = [\n\u001b[32m      6\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mPregunta 1: Categorias de mayor tendencia\u001b[39m\u001b[33m\"\u001b[39m, pre1_categorias_tendencia),\n\u001b[32m      7\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mPregunta 2: Categorias que mas/menos gustan\u001b[39m\u001b[33m\"\u001b[39m, pre2_categorias_mayor_menor_gusto),\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mPregunta 9: Prediccion de metricas\u001b[39m\u001b[33m\"\u001b[39m, pre9_prediccion_vistas_likes_dislikes)\n\u001b[32m     15\u001b[39m     ]\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=\u001b[38;5;28mlen\u001b[39m(preguntas), desc=\u001b[33m\"\u001b[39m\u001b[33mProcesando preguntas\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mcargar_y_limpiar_datos\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# cargar datos principales con progress bar\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAZUL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mCargando archivo CSV...\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mENDC\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_videos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# cargar mapeo de categorias\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data\\\\all-data\\\\INvideos_cc50_202101.csv'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    df = cargar_y_limpiar_datos()\n",
    "    \n",
    "    preguntas = [\n",
    "        (\"Pregunta 1: Categorias de mayor tendencia\", pre1_categorias_tendencia),\n",
    "        (\"Pregunta 2: Categorias que mas/menos gustan\", pre2_categorias_mayor_menor_gusto),\n",
    "        (\"Pregunta 3: Mejor ratio likes/dislikes\", pre3_mejor_ratio_likes_dislikes),\n",
    "        (\"Pregunta 4: Ratio vistas/comentarios\", pre4_ratio_vistas_comentarios),\n",
    "        (\"Pregunta 5: Volumen en el tiempo\", pre5_volumen_tendencia_tiempo),\n",
    "        (\"Pregunta 6: Canales mas/menos frecuentes\", pre6_canales_mayor_menor_tendencia),\n",
    "        (\"Pregunta 7: Estados con mas interacciones\", pre7_estados_vistas_interacciones),\n",
    "        (\"Pregunta 8: Tendencia vs comentarios\", pre8_tendencia_vs_comentarios_positivos),\n",
    "        (\"Pregunta 9: Prediccion de metricas\", pre9_prediccion_vistas_likes_dislikes)\n",
    "    ]\n",
    "    \n",
    "    with tqdm(total=len(preguntas), desc=\"Procesando preguntas\") as pbar:\n",
    "        for descripcion, funcion in preguntas:\n",
    "            funcion(df)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(f\"{VERDE}Analisis completado exitosamente{ENDC}\")\n",
    "    print(f\"Graficos guardados en: {MAGENTA}{graficos_dir}{ENDC}\")\n",
    "    print(f\"Datos geograficos en: {MAGENTA}{geo_dir}{ENDC}\")\n",
    "    print(f\"{SEPARADOR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ec206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
